{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T10:53:50.445534Z",
     "start_time": "2022-04-20T10:53:36.813531Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon, Ellipse\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_with_error(x,y,xerr,yerr):\n",
    "    z = x*y\n",
    "    zerr = z * ((xerr/x)**2 + (yerr/y)**2)**0.5\n",
    "    return z, zerr\n",
    "\n",
    "def division_with_error(x,y,xerr,yerr):\n",
    "    z = x/y\n",
    "    zerr = z * ((xerr/x)**2 + (yerr/y)**2)**0.5\n",
    "    return z, zerr\n",
    "\n",
    "def addition_with_error(x,y,xerr,yerr):\n",
    "    z= x+y\n",
    "    zerr = (xerr**2+yerr**2)**0.5\n",
    "    return z, zerr\n",
    "\n",
    "def subtraction_with_error(x,y,xerr,yerr):\n",
    "    z= x-y\n",
    "    zerr = (xerr**2+yerr**2)**0.5\n",
    "    return z, zerr\n",
    "\n",
    "division_with_error(0.91,0.47,0.1,0.06)\n",
    "multiplication_with_error(1.936,1.22,0.326,0.02)\n",
    "subtraction_with_error(1.58, 2.36192, 0.05, 0.3996)\n",
    "1.58-1.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular size calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(distance, size):\n",
    "    '''\n",
    "    distance and size in same units\n",
    "    Returns angle in radians (astropy units)\n",
    "    '''\n",
    "    angle = np.arctan(size/distance)\n",
    "    return angle\n",
    "\n",
    "def get_distance(angle, size):\n",
    "    '''\n",
    "    angle in astropy units\n",
    "    distance and size in same units\n",
    "    '''\n",
    "    distance = size/np.tan(angle)\n",
    "    return distance\n",
    "\n",
    "def get_size(angle, distance):\n",
    "    '''\n",
    "    angle in astropy units\n",
    "    distance and size in same units\n",
    "    '''\n",
    "#     angle = angle.to(u.rad)\n",
    "#     size  = distance*np.tan(angle.value)\n",
    "\n",
    "    size  = distance*np.tan(angle)\n",
    "    return size\n",
    "\n",
    "\n",
    "\n",
    "angle , distance, size = 1 ,  5000*u.pc , 2*u.pc\n",
    "\n",
    "angle = get_angle(distance, size)#.to(u.arcsec)\n",
    "\n",
    "distance = get_distance(angle, size)\n",
    "\n",
    "size = get_size(angle, distance)\n",
    "angle, size,distance\n",
    "\n",
    "\n",
    "\n",
    "def calc_angular_separation(ra1, dec1, ra2, dec2, plot=False):\n",
    "    '''\n",
    "    \n",
    "    ra : float or list\n",
    "        ra in degree\n",
    "    dec : float or list\n",
    "        dec in degree\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : float or list\n",
    "        cosγ = sinδ1 sinδ2 + cosδ1 cosδ2 cos(Δα) \n",
    "\n",
    "    '''\n",
    "    ra1 = np.radians(ra1)\n",
    "    dec1 = np.radians(dec1)\n",
    "    ra2 = np.radians(ra2)\n",
    "    dec2 = np.radians(dec2)\n",
    "\n",
    "    cos_theta = np.sin(dec1) * np.sin(dec2) + np.cos(dec1) * np.cos(dec2) * np.cos(np.abs(ra1-ra2))\n",
    "    theta = np.arccos(cos_theta)\n",
    "    \n",
    "    if plot:\n",
    "        pass\n",
    "    \n",
    "    return np.degrees(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astronomy formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 6.674e-11  # m3 kg-1 s-2\n",
    "Msun = 1.98847e30 # kg\n",
    "Rsun = 6.957e8 # m\n",
    "sigma = 5.670374419e-8   #W m−2 K−4\n",
    "Lsun = 3.828e26   #W\n",
    "\n",
    "# Reddening correction\n",
    "ZAMS['Gmag']= ZAMS['Gmag'] + dm + Ag_Av * Av\n",
    "ZAMS['bprp']= ZAMS['bprp'] + (Abp_Av - Arp_Av)*Av\n",
    "\n",
    "# number deisity profiles:\n",
    "# https://ned.ipac.caltech.edu/level5/Sept01/Bahcall2/Bahcall2_6.html\n",
    "def number_density(r, n0=100, Rc=1):  # spatial density profile\n",
    "    n = n0 * (1+ r**2/Rc**2)**-1.5\n",
    "    return n\n",
    "\n",
    "def luminosity_from_Mbol(Mbol):\n",
    "    L = 10**((4.8-Mbol)/2.5)\n",
    "    return L\n",
    "\n",
    "def distance_from_DM(mag):\n",
    "    return 10**(mag/5+1)\n",
    "\n",
    "def DM_from_distance(distance):\n",
    "    # distance in pc\n",
    "    return 5*np.log10(distance/10.)\n",
    "\n",
    "def L_from_M_logg_T(M, logg, T):\n",
    "    '''\n",
    "    M is mass in solar mass\n",
    "    logg is log of cgs surface gravity\n",
    "    T is temperature in Kelvin\n",
    "    '''\n",
    "    # Conversion to SI\n",
    "    M = M * Msun\n",
    "    g = 10**(logg) / 100.  # m/s2 \n",
    "    R = (G*M/g)**0.5\n",
    "    \n",
    "    L = 4 * np.pi * sigma * R**2 * T**4\n",
    "    \n",
    "    return L/Lsun\n",
    "\n",
    "def get_ZAMS(iso=iso,label_limit=12):\n",
    "    cl_iso_7               = iso[(iso.logAge == 7.00)& (iso.label < label_limit)]\n",
    "    cl_iso_75              = iso[(iso.logAge == 7.50)& (iso.label < label_limit)]\n",
    "    cl_iso_8               = iso[(iso.logAge == 8.00)& (iso.label < label_limit)]\n",
    "    cl_iso_9               = iso[(iso.logAge == 9.00)& (iso.label < label_limit)]\n",
    "    ZAMS_1 = cl_iso_7[(cl_iso_7.Gmag <= 1.5) & (cl_iso_7.Gmag > -4.0) & (iso.label < 2)]\n",
    "    ZAMS_2 = cl_iso_75[(cl_iso_75.Gmag <= 2.5) & (cl_iso_75.Gmag > 1.5)& (iso.label < 2) ]\n",
    "    ZAMS_3 = cl_iso_8[(cl_iso_8.Gmag > 2.5) & (iso.label < 2)]\n",
    "    ZAMS = pd.concat([ZAMS_1,ZAMS_2,ZAMS_3])\n",
    "    ZAMS = ZAMS.sort_values(by=['Gmag'])\n",
    "    return ZAMS\n",
    "ZAMS = get_ZAMS()\n",
    "\n",
    "\n",
    "def get_relations(isochrone, kind='linear'):\n",
    "    u_of_M = interpolate.interp1d(isochrone.Mini, isochrone.umag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    g_of_M = interpolate.interp1d(isochrone.Mini, isochrone.gmag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    r_of_M = interpolate.interp1d(isochrone.Mini, isochrone.rmag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    i_of_M = interpolate.interp1d(isochrone.Mini, isochrone.imag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    z_of_M = interpolate.interp1d(isochrone.Mini, isochrone.zmag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    y_of_M = interpolate.interp1d(isochrone.Mini, isochrone.ymag,kind=kind, bounds_error=False, fill_value=np.nan)\n",
    "    \n",
    "    return u_of_M,g_of_M,r_of_M, i_of_M,z_of_M,y_of_M\n",
    "\n",
    "# Errors in Gaia magnitudes\n",
    "def calc_e_Gmag(FG, e_FG):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    FG: float or list\n",
    "        flux\n",
    "    e_FG: float or list\n",
    "        error in flux\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    e_mag: float or list\n",
    "        Error in magnitude\n",
    "    '''\n",
    "    sigmaG_0 = 0.0027553202\n",
    "    return np.sqrt((-2.5/np.log(10)*e_FG/FG)**2 + sigmaG_0**2)\n",
    "def calc_e_GBPmag(FGBP, e_FGBP):\n",
    "    sigmaGBP_0 = 0.0027901700\n",
    "    return np.sqrt((-2.5/np.log(10)*e_FGBP/FGBP)**2 + sigmaGBP_0**2)\n",
    "def calc_e_Gmag(FGRP, e_FGRP):\n",
    "    sigmaGRP_0 = 0.0037793818\n",
    "    return np.sqrt((-2.5/np.log(10)*e_FGRP/FGRP)**2 + sigmaGRP_0**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading astronoimical files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_parsec_isochrone(file_name, skiprows=13):\n",
    "    '''\n",
    "    Reads the files downloaded from parsec website \n",
    "    (http://stev.oapd.inaf.it/cgi-bin/cmd) as pandas dataframe\n",
    "    Tested on CMD v3.6\n",
    "    '''\n",
    "    # Reading data\n",
    "    iso = pd.read_csv(file_name, engine='python',\n",
    "                      delimiter='\\s+', header=None, comment='#')\n",
    "    # reading column names\n",
    "    _df_column_names = pd.read_csv(file_name, engine='python', delim_whitespace=True, skipinitialspace=True,\n",
    "                                   skiprows=skiprows, nrows=1, header=None)\n",
    "    iso_column_names = _df_column_names.drop([0], axis=1).values[0]\n",
    "    # saving the column names to previously read file\n",
    "    iso.columns = iso_column_names\n",
    "    return iso\n",
    "iso_file_name = 'output690134726072.dat.txt'\n",
    "iso = read_parsec_isochrone(iso_file_name)\n",
    "\n",
    "\n",
    "def read_Panei_model(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\s+', header=None, comment='#')\n",
    "    df.columns=['logL','logT','logT6c','logRhoc','H1_s','logAge','logMH']\n",
    "    df.logAge = df.logAge+6.0\n",
    "    return df\n",
    "\n",
    "def read_Bergeron_model(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\s+', header=0, comment='#')\n",
    "    df['L'] = 10**((4.8-df['Mbol'])/2.5)\n",
    "    return df\n",
    "\n",
    "def read_Althaus_model(file_name):\n",
    "    df = pd.read_csv(file_name, sep='\\s+', header=None, comment='#')\n",
    "    df.columns=['LOG(L)','LOG(TEFF)','T_c','Ro_c','Hc','Hec','%Con_s','%Con_c','Log(edad/Myr)','Masa','M^dot','#modelo','Log(Lpp)','Log(Lcno)','Log(LHe)','Log(LCC)','int(dS/dt)','Log(Lnu)','Log MHtot','Log HeBuf','Masa_HFC','Masa_HeFC','Log(grav)','R/R_sun','L.H.[erg/s)]','Sep.Fase[erg/s]','periodo_orb(d)','masa secun']\n",
    "    time_start = 10**(df['Log(edad/Myr)'][0]+6)\n",
    "    df['Age'] = (10**(df['Log(edad/Myr)']+6)) - time_start\n",
    "    return df\n",
    "\n",
    "def read_VOSA_bestfitbin(file_name):\n",
    "    '''\n",
    "    Reads the files downloaded from VOSA\n",
    "    '''\n",
    "    # Reading data\n",
    "    df = pd.read_csv(file_name, engine='python',\n",
    "                      delimiter='\\s+', header=None, comment='#')\n",
    "    # giving column names\n",
    "    ## NOTE: One column name is empty, so it is taken as '---'\n",
    "    df.columns = ['Object','RA','DEC','D(pc)','Nobj','Model','mfid','Teff','logg','Meta.','more','Chi2','Md','---','Ftot','Ferr','Fobs/Ftot','Lbol','Lberr','MaxLam','Nfit','Ntot','Av','e_Teff','e_logg','e_Meta.','Teff_min','Teff_max','logg_min','logg_max','Meta_min','Meta_max','err_Av','Rad1','eRad1','Rad2','eRad2','M1','eM1','M2','eM2','Teff_min_68cl','Teff_max_68cl','Teff_min_96cl','Teff_max_96cl','logg_min_68cl','logg_max_68cl','logg_min_96cl','logg_max_96cl','Meta_min_68cl','Meta_max_68cl','Meta_min_96cl','Meta_max_96cl','Av_min_68cl','Av_max_68cl','Av_min_96cl','Av_max_96cl','Ftot_min_68cl','Ftot_max_68cl','Ftot_min_96cl','Ftot_max_96cl','Vgf','Vgfb']\n",
    "    return df\n",
    "file_name = 'temp/bestfitbin.dat'\n",
    "df_bestfitbin = read_VOSA_bestfitbin(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial-final mass relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T11:07:01.675079Z",
     "start_time": "2022-04-20T11:07:01.654535Z"
    }
   },
   "outputs": [],
   "source": [
    "def WD_from_MS(Mi):\n",
    "    if (Mi<0.87) | (Mi>8.2):\n",
    "        print ('give value between 0.87-8.2 Msun.')\n",
    "        Mf = np.nan\n",
    "    if (0.873 <= Mi) & (Mi < 2.8):\n",
    "        Mf = 0.0873*Mi+0.476\n",
    "    if (2.8 <= Mi) & (Mi < 3.65):\n",
    "        Mf = 0.181*Mi+0.21\n",
    "    if (3.65 <= Mi) & (Mi < 8.2):\n",
    "        Mf = 0.0835*Mi+0.565\n",
    "        \n",
    "    print ('Mi=%.3f --> Mf=%.3f ' %(Mi,Mf))\n",
    "    return Mf\n",
    "\n",
    "WD_from_MS(1.42)\n",
    "WD_from_MS(4.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WD mass age interpolation to get L and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_koester_interpolater(z_column, koester_filename = 'models/master_Bergeron_WD.csv', plot=False):\n",
    "    from scipy.interpolate import CloughTocher2DInterpolator\n",
    "    df_koester = pd.read_csv(koester_filename)\n",
    "    df_koester = df_koester[(df_koester.spectral_type=='DA') & (df_koester.Age>0)]\n",
    "    \n",
    "    x = np.log10(df_koester['mass'])\n",
    "    y = np.log10(df_koester['Age'])\n",
    "    z = df_koester[z_column]\n",
    "\n",
    "    interp = CloughTocher2DInterpolator(list(zip(x, y)), z)\n",
    "\n",
    "    if plot:\n",
    "        X = np.linspace(min(x), max(x), num=1000)\n",
    "        Y = np.linspace(min(y), max(y), num=1000)\n",
    "        X, Y = np.meshgrid(X, Y)  # 2D grid for interpolation\n",
    "        Z = interp(X, Y)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize =(8,8))\n",
    "        p0 = ax.pcolormesh(X, Y, Z, shading='auto')\n",
    "        p1 = ax.scatter(x, y, c=z,edgecolors='0.5')\n",
    "\n",
    "        p0.set_clim(p1.get_clim())\n",
    "        plt.colorbar(p1)\n",
    "        \n",
    "    return interp\n",
    "\n",
    "def get_LT_of_WD(age, mass, plot=False):\n",
    "    '''\n",
    "    age: yr\n",
    "    mass: Msun\n",
    "    '''\n",
    "    f_logTe = get_koester_interpolater('logTe')\n",
    "    f_logL  = get_koester_interpolater('logL')\n",
    "        \n",
    "    logTe = f_logTe(np.log10(mass), np.log10(age))\n",
    "    logL = f_logL(np.log10(mass), np.log10(age))\n",
    "    \n",
    "    if plot:\n",
    "        df_koester = pd.read_csv('mydata/master_Bergeron_WD.csv')\n",
    "        df_koester = df_koester[(df_koester.spectral_type=='DA') & (df_koester.Age>0)]\n",
    "        \n",
    "        plt.plot(df_koester['logTe'], df_koester['Age'], 'o', zorder=0)\n",
    "        plt.scatter(logTe, age, c='r', zorder=2)\n",
    "        plt.loglog()\n",
    "    return logTe, logL\n",
    "get_LT_of_WD([1e10, 1e9], [.26, 0.3], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T09:46:41.911872Z",
     "start_time": "2022-01-24T09:46:41.907456Z"
    }
   },
   "source": [
    "## UVIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPS_to_mag(CPS,ZP):\n",
    "    '''\n",
    "    CPS: counts per sec\n",
    "    ZP: zero point\n",
    "    '''\n",
    "    return -2.5*np.log10(CPS)+ZP\n",
    "\n",
    "\n",
    "CPS = 3159./27260.\n",
    "ZP = 18.016\n",
    "CPS_to_mag(CPS,ZP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T10:11:40.941002Z",
     "start_time": "2022-01-24T10:11:40.927253Z"
    }
   },
   "outputs": [],
   "source": [
    "def CPS_to_flux(CPS,UC):\n",
    "    '''\n",
    "    UC unit conversion factor\n",
    "    CPS: counts per second\n",
    "    '''\n",
    "    return CPS*UC\n",
    "\n",
    "def CPS_to_mag(CPS,ZP):\n",
    "    '''\n",
    "    CPS: counts per sec\n",
    "    ZP: zero point\n",
    "    '''\n",
    "    return -2.5*np.log10(CPS)+ZP\n",
    "\n",
    "def fnue_to_m_AB(fnue):\n",
    "    '''\n",
    "    fnue in Jy\n",
    "    '''\n",
    "    return -2.5*np.log10(fnue/3631.)\n",
    "\n",
    "def flambda_to_fnue(flambda,wavelength):\n",
    "    '''\n",
    "    wavelength in A\n",
    "    flambda in erg/cm2/s/A\n",
    "    returns fnue in jy\n",
    "    '''\n",
    "    return 33400. * wavelength**2 * flambda\n",
    "\n",
    "def fnue_to_flambda(fnue,wavelength):\n",
    "    '''\n",
    "    wavelength in A\n",
    "    fnue in jy\n",
    "    returns flambda in erg/cm2/s/A    \n",
    "    '''\n",
    "    return fnue / 33400. / wavelength**2\n",
    "\n",
    "CPS_to_mag(CPS,18.016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturation_correction(mag_psf_apr_corrected,filter_name):\n",
    "    ZP = filter_properties['ZP'][filter_name]\n",
    "    print('Applying saturation correction for %s filter with ZP=%.2f' %(filter_name,ZP))\n",
    "    CPS = 10**((ZP-mag_psf_apr_corrected)/2.5)\n",
    "    CPF = CPS/28.7\n",
    "    CPF5 = CPF*0.97\n",
    "    ICPF5 = -1*np.log(1-CPF5)\n",
    "    ICORR = ICPF5-CPF5\n",
    "    RCORR = ICORR*(0.89-0.3*ICORR**2)\n",
    "    CPF_corr = CPF+RCORR\n",
    "    CPS_corr = CPF_corr*28.7\n",
    "    mag_AB_corr = -2.5*np.log10(CPS_corr)+ZP\n",
    "    mag_AB_corr_round = np.round(mag_AB_corr, 3)\n",
    "    return mag_AB_corr_round\n",
    "\n",
    "filter_properties = pd.DataFrame(columns = ['Name','wavelength', 'ZP' , 'e_ZP'])\n",
    "\n",
    "filter_properties['Name'] = ['F148W','F154W','F169M','F172M','N242W','N219M','N245M','N263M','N279N']\n",
    "filter_properties['wavelength'] = [1481, 1541, 1608, 1717, 2418, 2196, 2447, 2632, 2792]\n",
    "filter_properties['ZP'] = [18.097, 17.771, 17.410, 16.274, 19.763, 16.654, 18.452, 18.146, 16.416]\n",
    "filter_properties['e_ZP'] = [0.010,0.010,0.010,0.020,0.002,0.020,0.005,0.010,0.010]\n",
    "\n",
    "filter_properties = filter_properties.set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# histogram\n",
    "bins=[0,0.5,1.0,5]\n",
    "h0, _ =np.histogram(BSS_85_90.mass_excess,bins=bins)\n",
    "\n",
    "# add two arrays one oafter another\n",
    "np.append(pBS_85_90.mass_excess,BSS_85_90.mass_excess)\n",
    "\n",
    "# points between 0 and 1 at 0.2 step\n",
    "np.arange(0,1,0.2)\n",
    "\n",
    "# condition, when True, when False\n",
    "np.where(a < 5, a, 10*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read text file with \",\" delimiter and header\n",
    "BSS_data = pd.read_csv('outputs/region_12_5_better_3_clMass.txt',engine='python',delimiter= ',', header=0)\n",
    "# ascii file with comments and emply space as delimiter\n",
    "iso = pd.read_csv('data/isochrone_Gaia_eDR3.txt',skiprows=(0,1,2,3,4,5,6,7,8,9,10,11) ,engine='python',delimiter= '\\s+', header=0, comment='#')\n",
    "\n",
    "# indexing\n",
    "cant20 = cant20.set_index('Cluster')\n",
    "_iso_cut.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "data.rename(columns={'ra_1':'ra_Gaia', 'dec_1':'dec_Gaia'}, \n",
    "            inplace=True)\n",
    "\n",
    "# mean of columns as new column\n",
    "data['ra_UVIT'] = data[['ra_2','ra_3']].mean(axis=1)\n",
    "\n",
    "# removing/dropping columns\n",
    "df.drop(columns=['B', 'C'])\n",
    "# dropping rows\n",
    "df.drop([0, 1])\n",
    "\n",
    "# Adding new column \"A\" at a given (2nd) position\n",
    "df.insert(loc=2, column='A', value=new_col)\n",
    "\n",
    "# rounding\n",
    "lumi_func = lumi_func.round({'logAge':2})\n",
    "table2 = table2.round({'RA_ICRS':6, 'DE_ICRS':6, 'Gmag':3,'BP-RP':3, 'mass':2, 'M_e':3})\n",
    "\n",
    "# unique values in a column\n",
    "BSS_data_1000.Cluster.unique()\n",
    "\n",
    "# sorting\n",
    "BSS_data_1000 = BSS_data_1000.sort_values(by=['Cluster', 'Gmag'])\n",
    "\n",
    "# Selecting subset\n",
    "cl_iso_7 = iso[(iso.logAge == 7.00)& (iso.label < label_limit)]\n",
    "\n",
    "cat_cluster = cat_cluster.loc[cluster_list]\n",
    "\n",
    "# create a subset of brightest BSS in each cluster\n",
    "BSS_brightest = BSS_data_1000.groupby('Cluster', group_keys=False).apply(lambda df: df.head(1))\n",
    "\n",
    "# drop points with NaN for mass\n",
    "interpolated_model = interpolated_model[interpolated_model['mass'].notna()]\n",
    "\n",
    "# concatinating dataframes below one another\n",
    "ZAMS = pd.concat([ZAMS_1,ZAMS_2,ZAMS_3])\n",
    "\n",
    "# closest values in column\n",
    "ZAMS_closest = ZAMS.iloc[(ZAMS['Gmag']-M_G).abs().argsort()[:1]]\n",
    "\n",
    "# horizontal stacking / concatenation\n",
    "iso = pd.concat([iso, _iso], axis=1)\n",
    "\n",
    "# inputting one value in i'th row\n",
    "data_chi.loc[i, 'Teff']   = Teff\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "conditions = [\n",
    "    (cluster_0_short['P_PRF_2r_103'] >= thre),\n",
    "    (cluster_0_short['P_PRF_2r_103'] < thre) & (cluster_0_short['P_PRF_2r_64'] >= thre),\n",
    "    (cluster_0_short['P_PRF_2r_103'] < thre) & (cluster_0_short['P_PRF_2r_64'] < thre)    \n",
    "    ]\n",
    "values = ['M', 'C', 'F']\n",
    "cluster_0_short['class'] = np.select(conditions, values,default='nG')\n",
    "\n",
    "# simple condition\n",
    "data[filter_name+'_sat'] = np.select([(data[filter_name]<ZP-2.5)], [ZP-2.5], default=np.nan)\n",
    "\n",
    "# displaying all columns\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_bestfitbin.head())\n",
    "    \n",
    "# Summary statistics like mean, count, max, min...\n",
    "df_bestfitbin.describe()\n",
    "\n",
    "# get frequency or counts of an column\n",
    "df_likely_search_results['name'].value_counts()\n",
    "\n",
    "    \n",
    "# save file\n",
    "table2.to_csv(DIR_cds + 'tableA2_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon, Ellipse\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "\n",
    "# creating subplots\n",
    "# projection{None, 'aitoff', 'hammer', 'lambert', 'mollweide', 'polar', 'rectilinear', str}\n",
    "fig, ax = plt.subplots(figsize =(20,10), ncols=4, nrows=2, sharex=True,sharey='row',aspect='equal') #'col'\n",
    "[axi.set_axis_off() for axi in ax.ravel()]\n",
    "ax[0][0] = fig.add_axes([0.04, 0.56, 0.16, 0.40])\n",
    "# [left, bottom, width, height]\n",
    "# wspace: the amount of width reserved for space between subplots, expressed as a fraction of the average axis width\n",
    "fig.subplots_adjust(left=0.125,right=0.9,bottom=0.1,top=0.9,wspace=0.2,hspace=0.2)\n",
    "\n",
    "# plotting\n",
    "ax.plot([Ax,Bx,Cx,Dx], [Ay,By,Cy,Dy], marker='+',markersize=10,c='lime', ls='',label='')\n",
    "ax.scatter(ZAMS_red['bprp'],ZAMS_red['Gmag'],c='m',alpha=1, marker='.',s=5, zorder=2,label='ZAMS')\n",
    "\n",
    "# hallow markers\n",
    "ax[1].plot(np.log10(subsample.cl_mass),np.log10(subsample.len_BSS/subsample.stars_near_TO_model),label='$N_{BSS} < 5$',c='deepskyblue',lw=0, marker='o', fillstyle='none',zorder=1)\n",
    "\n",
    "\n",
    "# colorbar\n",
    "colorbar_plot = ax[0].scatter(Gap_data.pmR0,Gap_data.parallax, c=Gap_data.pmR0, cmap='jet')\n",
    "# colorbar with scales colormap\n",
    "p1 = ax[1].scatter((subsample.cl_mass),y,c=subsample.len_BSS,s=20,label='',zorder=3,cmap='nipy_spectral_r',norm=matplotlib.colors.PowerNorm(gamma=0.5))\n",
    "colorbar_plot.set_clim(0,pmR0_max)\n",
    "fig.colorbar(colorbar_plot, cax=ax[1], label='color')\n",
    "\n",
    "# colorbar scaling\n",
    "plt.scatter(x,y,edgecolors='none',s=marker_size,c=void_fraction,\n",
    "                norm=matplotlib.colors.LogNorm())\n",
    "\n",
    "\n",
    "# creating descrete colorbar\n",
    "from matplotlib.colors import ListedColormap\n",
    "def get_colorbar():\n",
    "    # Create a colormar for WHAN\n",
    "    cmap = ListedColormap(['green','orange', 'blue', 'blue', 'blue', 'blue'])\n",
    "    col_dict={0:\"green\",\n",
    "              1:\"orange\",\n",
    "              2:\"blue\",\n",
    "              3:\"blue\",\n",
    "              4:\"blue\",\n",
    "              5:\"blue\"}\n",
    "    # We create a colormar from our list of colors\n",
    "    cm = ListedColormap([col_dict[x] for x in col_dict.keys()])\n",
    "    # Let's also define the description of each category : \n",
    "    labels = np.array(['MT','merger', 'multi','','',''])\n",
    "    len_lab = len(labels)\n",
    "    # prepare normalizer\n",
    "    norm_bins = np.sort([*col_dict.keys()]) + 0.5\n",
    "    norm_bins = np.insert(norm_bins, 0, np.min(norm_bins) - 1.0)\n",
    "    # Make normalizer and formatter\n",
    "    norm = matplotlib.colors.BoundaryNorm(norm_bins, len_lab, clip=True)\n",
    "    fmt = matplotlib.ticker.FuncFormatter(lambda x, pos: labels[norm(x)])\n",
    "    diff = norm_bins[1:] - norm_bins[:-1]\n",
    "    tickz = norm_bins[:-1] + diff / 2\n",
    "    return cm, fmt, tickz\n",
    "cmap, fmt, tickz =get_colorbar() \n",
    "# use case:\n",
    "p22 = ax[2,2].scatter(MEM_data['BP-RP'],MEM_data['Gmag'], c=MEM_data['Evol'],cmap=cmap)\n",
    "plt.colorbar(p22, ax=ax[2,2], label='Evol', format=fmt,ticks=tickz)\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('jet', 20)   # 20 discrete colors\n",
    "\n",
    "\n",
    "# Getting individual colors from a colormap\n",
    "cmap = matplotlib.cm.get_cmap('tab10')\n",
    "rgba = cmap(0)    # (0.0 to 1.0)\n",
    "# getting color list from colormap\n",
    "color_list =plt.cm.rainbow(np.linspace(0,1,N))  # creates array of N colors\n",
    " \n",
    "# linestyles\n",
    "ls=(5,(5,5))\n",
    "'dotted' = (0,(1,1))\n",
    "'dashed' = (0,(5,5))\n",
    "'dashdotted' = (0,(3,1,1,1))\n",
    "loosely dashed = (0,(5,10))\n",
    "\n",
    "# filling area between (x,y1), (x,y2) plots\n",
    "ax[2][0].fill_between(x,y1,y2,color='g',alpha=0.2)\n",
    "\n",
    "# axis limits\n",
    "ax.invert_yaxis()\n",
    "# stop autoscale\n",
    "ax.autoscale(False)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(Ax-0.3,Cx+0.1)\n",
    "ax.set_ylim(Ay+0.5,By-0.5)\n",
    "\n",
    "# taking xlim and ylims from one axis to another\n",
    "ax[1].set_xlim(ax[0].get_xlim())\n",
    "ax[1].set_ylim(ax[0].get_ylim())\n",
    "\n",
    "# Adding vertical and horizontal lines\n",
    "ax.axvline(x,color='0.5',lw=1)\n",
    "ax.axhline(x,color='0.5',lw=1)\n",
    "\n",
    "\n",
    "# Patches\n",
    "rectangle = Polygon(((x0,y0), (x0,y1), (x1,y1), (x1,y0)),fc='yellow', ec=(0,0,0,0), lw=1, zorder=0)        \n",
    "ax.add_artist(rectangle)\n",
    "\n",
    "ellipse = Ellipse((cl_pmra, cl_pmdec ),width= cl_pmra_std,height= cl_pmdec_std, edgecolor='g', facecolor=None,fill=False, lw=1, zorder=5)\n",
    "ax.add_artist(ellipse)\n",
    "    \n",
    "coo_10 =[(Ax-0.1,By-0.75),(Ax,By-0.75),(Ax,Ay),(Ax-0.1,Ay),(Ax-0.1,By)]\n",
    "path_10 = Path(coo_10)\n",
    "patch_10 = patches.PathPatch(path_10, fc='none', ec='r', lw=2)\n",
    "ax.add_patch(patch_10)\n",
    "\n",
    "# ticks and label details\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "plt.setp(ax[0][1].get_yticklabels(),visible=False)\n",
    "ax[0][0].tick_params(which='both', direction='in', length=5)\n",
    "\n",
    "# major minor ticks\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.2))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax.grid(which='major', color='0.7', linestyle='-',zorder=0)\n",
    "ax.grid(which='minor', color='0.8', linestyle='--',zorder=0)\n",
    "\n",
    "# spine colors\n",
    "ax[2][0].spines['bottom'].set_color('r')\n",
    "ax[2][0].spines['top'].set_color('r') \n",
    "ax[2][0].spines['right'].set_color('r')\n",
    "ax[2][0].spines['left'].set_color('r')\n",
    "\n",
    "# Texts: labels and titles\n",
    "ax.set_title(cl_name)\n",
    "ax[0][0].set_ylabel('M$_G$ [mag]')\n",
    "ax[0][0].set_xlabel('G$_{BP} -$ G$_{RP}$ [mag]')\n",
    "ax.set(xlabel='bp-rp', ylabel='g',title=cl_name)    \n",
    "ax[0][0].text(0.05, 0.95, '(a)', fontsize=12, transform=ax[0][0].transAxes)\n",
    "ax.legend(loc='lower right',   # 'upper left', 'center right'    \n",
    "          bbox_to_anchor=(0.5, 0., 0.5, 0.5),   # legend will be placed in this box accounting for loc \n",
    "          framealpha = 0.8, borderpad = 0.4. labelspacing=0.5,\n",
    "          columnspacing=2.0,ncol=1) \n",
    "\n",
    "\n",
    "axins = ax[1].inset_axes([0.2, 0.15, 0.79, 0.84])\n",
    "xmax = np.ceil(np.nanmax(1/df_bin['frequency_veb']))\n",
    "bins = np.arange(0,xmax+1, 1)\n",
    "axins.hist(1/df_bin['frequency_veb'], alpha=0.5, label='Variable EB (%d)'%(df_bin.has_veb.sum()),bins=bins, color='C0')\n",
    "\n",
    "\n",
    "# saving\n",
    "plt.savefig('plots/CMD_simple/'+cl_name+'_2.png', format='png',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random colormap\n",
    "def rand_cmap(nlabels, type='bright', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "    \n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in range(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in range(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap,randRGBcolors\n",
    "\n",
    "\n",
    "new_cmap,_ = rand_cmap(20, type='bright', first_color_black=False, last_color_black=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#boxplots by manual binning first\n",
    "AgeNN_binned = np.round(better_clusters.AgeNN.values/0.25,0)*0.25\n",
    "sns.boxplot(AgeNN_binned,better_clusters.Rnorm_BSS_mean,ax=ax[0][0],width=0.6)\n",
    "\n",
    "sns.pairplot(subsample,vars=['log_N_BSS','log_N_TO','AgeNN','log_N_relax','log_mass','log_density','log_fraction'], corner=True,kind=\"hist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.gaia import Gaia\n",
    "\n",
    "adql_job =  \"select top 1999 \"+\\\n",
    "            \"ra, dec \"+\\\n",
    "            \"FROM gaiadr2.gaia_source WHERE \"+\\\n",
    "            \"parallax is not null and \"+\\\n",
    "            \"ABS(parallax-\"+str(parallax_limit)+\")>parallax_error and \"+\\\n",
    "            \"contains(point('icrs',gaiadr2.gaia_source.ra,gaiadr2.gaia_source.dec), \"+\\\n",
    "            \"circle('icrs',\"+str(ra)+\",\"+str(dec)+\",\"+str(radius)+\"))=1\"\n",
    "\n",
    "adql_job_averaged = \"select top 1999 \"+\\\n",
    "                \"AVG(pmra) AS field_pmra, AVG(pmdec) AS field_pmdec, STDDEV(pmra) AS field_pmra_std, STDDEV(pmdec) AS field_pmdec_std \"+\\\n",
    "                \"FROM gaiadr2.gaia_source WHERE \"+\\\n",
    "                \"pmra < 200 and pmra > -50 and pmdec < 50 and pmdec > -100 and \"+\\\n",
    "                \"parallax is not null and \"+\\\n",
    "                \"ABS(parallax-\"+str(parallax_limit)+\")>parallax_error and \"+\\\n",
    "                \"contains(point('icrs',gaiadr2.gaia_source.ra,gaiadr2.gaia_source.dec), \"+\\\n",
    "                \"circle('icrs',\"+str(ra)+\",\"+str(dec)+\",\"+str(radius)+\"))=1\"\n",
    "try:\n",
    "    job = Gaia.launch_job(adql_job)\n",
    "    r = job.get_results()\n",
    "    # print(r)\n",
    "    return r\n",
    "except:\n",
    "    print ('No field star found near %s' %cl_name)\n",
    "    return [[0.,0.,0.,0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# printing\n",
    "print(\"slope:     {} +/- {}\".format(p[0], np.sqrt(V[0][0])))\n",
    "print('Clusters with $N_{BSS}\\geq10$\\n$N_{BSS} \\propto M^{%.2f}$' %(m))\n",
    "\n",
    "\n",
    "def print_progress(current_iteration, total_iterations=100, step=50, message='Progress'): \n",
    "    if (current_iteration%step==0):\n",
    "        print ('\\r %s:  %d/%d  (%d%%)' %(message, current_iteration+1, total_iterations, 100*(current_iteration+1)/total_iterations), end='')\n",
    "def reprint(message):\n",
    "    print ('\\r %s' %(message), end='')\n",
    "\n",
    "        \n",
    "# Create folder is not present\n",
    "if not os.path.exists('plots/stamps'): os.makedirs('plots/stamps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cone search \n",
    "def get_gaiadr3_cone(ra, dec, radius=60./3600, ROW_LIMIT=1000, quick=False):\n",
    "    Gaia.ROW_LIMIT = ROW_LIMIT  # Ensure the default row limit.\n",
    "    coord = SkyCoord(ra=ra, dec=dec, unit=(u.degree, u.degree), frame='icrs')\n",
    "    radius = u.Quantity(radius, u.deg)\n",
    "    if quick: columns = ['source_id', 'ra', 'dec' , 'parallax', 'pmra', 'pmdec', 'phot_g_mean_mag', 'bp_rp']\n",
    "    else:     columns = []\n",
    "    j = Gaia.cone_search(coord, radius, columns=columns)\n",
    "    r = j.get_results()\n",
    "    r.pprint()\n",
    "    return r\n",
    "\n",
    "\n",
    "# plotting pseudo image from Gaia data\n",
    "def plot_gaia_image(gaia_neighbourhood, ax=None):\n",
    "    if ax == None: fig, ax = plt.subplots(figsize =(8,8))\n",
    "    \n",
    "    gaia_neighbourhood['22-G'] = 22-gaia_neighbourhood['phot_g_mean_mag']\n",
    "    g = sns.scatterplot(\n",
    "        x=gaia_neighbourhood['ra'], y=gaia_neighbourhood['dec'],\n",
    "        hue=gaia_neighbourhood['bp_rp'], size=gaia_neighbourhood['22-G'],\n",
    "        palette='coolwarm', sizes=(10, 200), ax=ax)\n",
    "    \n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
